Considere o código em C abaixo, que é um programa que utiliza pool de threads para
resolver o problema de particionar um vetor.

```
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>
#include <pthread.h>
#include <stdatomic.h>
#include "chrono.h"

// N_PART, o número de partições é definido na compilação
#define INPUT_SIZE 8000000
#define CACHE_REPS 32
#define MAX_THREADS 64
#define NTIMES 10

pthread_barrier_t pool_barrier;
atomic_int active_threads;

typedef struct {
        long long *input;
        long long *p;
        long long *output;
        int *pos;
        atomic_int *faixa_index;
        int n;
        int np;
        int start;
        int end;
        int thread_id;
        int num_threads;
} ThreadData;

typedef struct {
        pthread_t thread;
        ThreadData *task_data;
        int is_active;
} ThreadPool;

ThreadPool thread_pool[MAX_THREADS];

int cmp_long_long(const void *a, const void *b) {
        long long x = *(const long long *)a;
        long long y = *(const long long *)b;
        return (x > y) - (x < y);
}

int *alocarVetorInt(int size) {
        int *arr = malloc(sizeof(int) * size);
        return arr;
}

long long *alocarVetorLL(int size) {
        long long *arr = malloc(sizeof(long long) * size);
        return arr;
}

long long geraAleatorioLL() {
        int a = rand();
        int b = rand();
        return (long long)a * 100 + b;
}

void verifica_particoes(long long *input, int n, long long *p, int np, long long *output, int *pos) {
        for (int i = 0; i < np; i++) {
                int start = pos[i];
                int end = (i == np - 1) ? n : pos[i + 1];
                for (int j = start; j < end; j++) {
                        if ((i == 0 && output[j] >= p[i]) || (i > 0 && (output[j] < p[i - 1] || output[j] >= p[i]))) {
                                printf("Erro: Elemento %lld na posição %d fora da faixa [%lld, %lld)\n", output[j], j, (i > 0 ? p[i - 1] : 0), p[i]);
                                return;
                        }
                }
        }
        printf("Particionamento sem erros\n");
}

int busca_binaria(long long *p, int np, long long value) {
        int inicio = 0, fim = np - 1;
        while (inicio < fim) {
                int meio = (inicio + fim) / 2;
                if (value < p[meio]) {
                        fim = meio;
                } else {
                        inicio = meio + 1;
                }
        }
        return inicio;
}

void *thread_pool_worker(void *arg) {
        ThreadPool *thread = (ThreadPool *)arg;
        while (1) {
                pthread_barrier_wait(&pool_barrier);
                if (!thread->is_active) break;

                ThreadData *data = thread->task_data;
                for (int i = data->start; i < data->end; i++) {
                        int faixa = busca_binaria(data->p, data->np, data->input[i]);
                        int idx = atomic_fetch_add(&data->faixa_index[faixa], 1);
                        data->output[idx] = data->input[i];
                }
                atomic_fetch_sub(&active_threads, 1);
        }
        return NULL;
}

void create_thread_pool(int num_threads) {
        pthread_barrier_init(&pool_barrier, NULL, num_threads + 1);
        for (int i = 0; i < num_threads; i++) {
                thread_pool[i].is_active = 1;
                pthread_create(&thread_pool[i].thread, NULL, thread_pool_worker, &thread_pool[i]);
        }
}

void shutdown_thread_pool(int num_threads) {
        for (int i = 0; i < num_threads; i++) {
                thread_pool[i].is_active = 0;
        }
        pthread_barrier_wait(&pool_barrier);
        for (int i = 0; i < num_threads; i++) {
                pthread_join(thread_pool[i].thread, NULL);
        }
        pthread_barrier_destroy(&pool_barrier);
}

void multi_partition(long long *input, int n, long long *p, int np, long long *output, int *pos, int num_threads) {
        int *faixa_count = calloc(np, sizeof(int));
        atomic_int *faixa_index = malloc(sizeof(atomic_int) * np);
        for (int i = 0; i < np; i++) atomic_init(&faixa_index[i], 0);

        for (int i = 0; i < n; i++) faixa_count[busca_binaria(p, np, input[i])]++;

        pos[0] = 0;
        for (int i = 1; i < np; i++) {
                pos[i] = pos[i - 1] + faixa_count[i - 1];
                atomic_store(&faixa_index[i], pos[i]);
        }

        int chunk_size = (n + num_threads - 1) / num_threads;
        active_threads = num_threads;

        for (int i = 0; i < num_threads; i++) {
                thread_pool[i].task_data = malloc(sizeof(ThreadData));
                *thread_pool[i].task_data = (ThreadData){input, p, output, pos, faixa_index, n, np, i * chunk_size, (i + 1) * chunk_size < n ? (i + 1) * chunk_size : n, i, num_threads};
        }

        pthread_barrier_wait(&pool_barrier);
        while (atomic_load(&active_threads) > 0);

        free(faixa_count);
        free(faixa_index);
}

int main(int argc, char *argv[]) {

        if (argc != 2) {
                printf("Usage: %s <num_threads>\n", argv[0]);
                return EXIT_FAILURE;
        }

        int num_threads = atoi(argv[1]);
        if (num_threads <= 0 || num_threads > MAX_THREADS) {
                printf("Invalid number of threads. Use between 1 and %d.\n", MAX_THREADS);
                return EXIT_FAILURE;
        }

        srand(33);

        long long *input = alocarVetorLL(INPUT_SIZE);
        long long *p = alocarVetorLL(N_PART * CACHE_REPS);
        long long *output = alocarVetorLL(INPUT_SIZE);
        int *pos = alocarVetorInt(N_PART);

        int n = INPUT_SIZE;
        int np = N_PART;

        chronometer_t parallelMultiPartitionTime;

        for (int i = 0; i < INPUT_SIZE; i++) input[i] = geraAleatorioLL();
        for (int i = 0; i < N_PART - 1; i++) p[i] = geraAleatorioLL();
        p[N_PART - 1] = LLONG_MAX;

        qsort(p, N_PART, sizeof(long long), cmp_long_long);

        // o vetor p contém varias repeticoes das particoes
        // para evitar os efeitos de caching
        for (int i = 0; i < CACHE_REPS; i++) {
                memcpy(p + i * np, p, np * sizeof(*p));
        }
        
        chrono_reset(&parallelMultiPartitionTime);
        chrono_start(&parallelMultiPartitionTime);

        long long *tmp_p = p;
        create_thread_pool(num_threads);
        for (int i = 0; i < NTIMES; i++) {
                multi_partition(input, n, tmp_p, np, output, pos, num_threads);
                verifica_particoes(input, n, tmp_p, np, output, pos);

                // Aqui, o ponteiro_p tmp é atualizado para apontar para uma cópia
                // diferente de p 
                tmp_p += np;
        }
        shutdown_thread_pool(num_threads);

        chrono_stop(&parallelMultiPartitionTime);
        double total_time_in_seconds = (double)chrono_gettotal(&parallelMultiPartitionTime) / 1e9;

        chrono_reportTime(&parallelMultiPartitionTime, "multiPartitionTime");
        printf("%.6f\n", total_time_in_seconds);

        free(input);
        free(p);
        free(output);
        free(pos);
        return 0;
}
```

busque fazer as seguintes melhorias:

Paralelização das Contagens Locais: Cada thread deve fazer a contagem de elementos dentro de suas partições locais antes de sincronizar e atualizar os contadores globais.
Redução de Barreiras: A barreira deve ser mantida apenas para sincronização mínima nas fases críticas.


Gere o código com as melhorias propostas
